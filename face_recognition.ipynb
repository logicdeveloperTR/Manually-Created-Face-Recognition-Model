{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import random\n",
    "import xarray as xr\n",
    "from dask.array.image import imread\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "print(\"done\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_virtual_device_configuration(\n",
    "    #gpus[0],\n",
    "   # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "face_cascade = cv2.CascadeClassifier('faces.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n"
     ]
    }
   ],
   "source": [
    "print(\"START\")\n",
    "def imread_f(filename):\n",
    "    item=cv2.imread(filename)\n",
    "    return item\n",
    "def preprocessing(item):\n",
    "    gray = cv2.cvtColor(item, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        new_im=item[y:y+h,x:x+w,:]\n",
    "        new_im=cv2.resize(new_im, (160, 160)).astype(np.float32)\n",
    "        new_im=(new_im-np.mean(new_im))/np.std(new_im)\n",
    "        return new_im\n",
    "    res=cv2.resize(item, (160, 160)).astype(np.float32)\n",
    "    res=(res-np.mean(res))/np.std(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ozano\\AppData\\Local\\Temp\\ipykernel_20164\\3143152583.py:23: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "END\n",
      "[[[[-0.0545023   0.08628052  0.06868267]\n",
      "   [-0.0545023   0.08628052  0.08628052]\n",
      "   [-0.01930659  0.13907409  0.13907409]\n",
      "   ...\n",
      "   [ 0.33265045  0.42063972  0.40304187]\n",
      "   [ 0.40304187  0.49103114  0.4734333 ]\n",
      "   [ 0.36784616  0.45583543  0.43823758]]\n",
      "\n",
      "  [[-0.00170874  0.08628052  0.08628052]\n",
      "   [-0.00170874  0.08628052  0.10387838]\n",
      "   [-0.00170874  0.08628052  0.13907409]\n",
      "   ...\n",
      "   [ 0.3502483   0.45583543  0.43823758]\n",
      "   [ 0.3502483   0.45583543  0.43823758]\n",
      "   [ 0.40304187  0.49103114  0.4734333 ]]\n",
      "\n",
      "  [[-0.00170874  0.06868267  0.13907409]\n",
      "   [-0.00170874  0.05108482  0.12147623]\n",
      "   [-0.03690444  0.01588911  0.10387838]\n",
      "   ...\n",
      "   [ 0.36784616  0.45583543  0.43823758]\n",
      "   [ 0.40304187  0.50862896  0.49103114]\n",
      "   [ 0.38544402  0.45583543  0.45583543]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.6559069  -1.1279713  -1.6559069 ]\n",
      "   [-1.6031133  -1.1807649  -1.5855155 ]\n",
      "   [-1.5503198  -1.2511563  -1.4975262 ]\n",
      "   ...\n",
      "   [-1.4447327  -1.1983627  -1.2335584 ]\n",
      "   [-1.3743412  -1.1983627  -1.2335584 ]\n",
      "   [-1.3215476  -1.2159606  -1.2335584 ]]\n",
      "\n",
      "  [[-1.6207112  -1.0575799  -1.6207112 ]\n",
      "   [-1.5679176  -1.1455692  -1.5679176 ]\n",
      "   [-1.4623305  -1.163167   -1.409537  ]\n",
      "   ...\n",
      "   [-1.409537   -1.1807649  -1.2159606 ]\n",
      "   [-1.3567433  -1.1807649  -1.1983627 ]\n",
      "   [-1.3391455  -1.1983627  -1.2159606 ]]\n",
      "\n",
      "  [[-1.4975262  -1.0223842  -1.5327219 ]\n",
      "   [-1.4799284  -1.0751778  -1.5151241 ]\n",
      "   [-1.4271348  -1.1103735  -1.4623305 ]\n",
      "   ...\n",
      "   [-1.3567433  -1.163167   -1.1983627 ]\n",
      "   [-1.3039498  -1.1279713  -1.1807649 ]\n",
      "   [-1.2511563  -1.0927756  -1.1279713 ]]]]\n",
      "END\n",
      "-6.357829e-08\n",
      "1.2715658e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202599, 160, 160, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def face_detector(path):\n",
    "    im=cv2.imread(path)\n",
    "    gray=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    photo=None\n",
    "    c=0\n",
    "    for (x, y, w, h) in faces:\n",
    "        photo=im[y:y+h,x:x+w,:]\n",
    "        photo=cv2.resize(photo, (160, 160))\n",
    "        im_=photo.astype(np.float32)\n",
    "        im_=(im_-np.mean(im_))/np.std(im_)\n",
    "        c=1\n",
    "    if c==1:\n",
    "        return im_.reshape(1, 160, 160, 3)\n",
    "    return None\n",
    "def if_n(img, l):\n",
    "    if img is None:\n",
    "        return\n",
    "    else:\n",
    "        l.append(img)\n",
    "        return\n",
    "l_positive=[]\n",
    "gpu_available = tf.test.is_gpu_available()\n",
    "print(gpu_available)\n",
    "path_ =\"./Humans\"\n",
    "pathes=os.listdir(\"./Humans\")\n",
    "images_negative=[]\n",
    "im_1, anchor = face_detector('./positive_anchor/photo_positive.jpg'), face_detector('./positive_anchor/photo_anchor.jpg')\n",
    "if_n(im_1, l_positive)\n",
    "if_n(face_detector('./positive_anchor/p_2.jpg'), l_positive)\n",
    "if_n(face_detector('./positive_anchor/p_3.jpg'), l_positive)\n",
    "if_n(face_detector('./positive_anchor/p_4.jpg'), l_positive)\n",
    "if_n(face_detector('./positive_anchor/p_5.jpg'), l_positive)\n",
    "l_positive=np.array(l_positive)\n",
    "print(\"END\")\n",
    "print(l_positive[0])\n",
    "print(\"END\")\n",
    "print(np.mean(l_positive[0]))\n",
    "print(np.mean(anchor))\n",
    "l_p=len(l_positive)\n",
    "c=4\n",
    "\n",
    "\n",
    "ims=imread('./Humans/img_align_celeba/*.jpg', imread=imread_f, preprocess=preprocessing).astype(np.float32)\n",
    "ims.shape\n",
    "#ims=ims.to_dask_array(lengths=True)\n",
    "#ims=ims.reshape((ims.shape[0], 160, 160, 3))\n",
    "#ims=ims.map_blocks(func, (x), dtype=np.float32)\n",
    "#ims=ims.map_overlap(func, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.8733778 , -1.8733778 , -1.8733778 ],\n",
       "        [-1.8733778 , -1.8908063 , -1.8908063 ],\n",
       "        [-1.8559494 , -1.8908063 , -1.8908063 ],\n",
       "        ...,\n",
       "        [-1.0890969 , -0.86252683,  0.07861026],\n",
       "        [-1.2110962 , -1.0019546 , -0.06081746],\n",
       "        [-1.3330954 , -1.1239538 , -0.18281671]],\n",
       "\n",
       "       [[-1.8733778 , -1.8908063 , -1.8908063 ],\n",
       "        [-1.8559494 , -1.8908063 , -1.8908063 ],\n",
       "        [-1.8559494 , -1.8908063 , -1.8908063 ],\n",
       "        ...,\n",
       "        [-1.1588107 , -0.96709764,  0.0088964 ],\n",
       "        [-1.2110962 , -1.0019546 , -0.043389  ],\n",
       "        [-1.2459531 , -1.05424   , -0.07824592]],\n",
       "\n",
       "       [[-1.8385209 , -1.8733778 , -1.9082347 ],\n",
       "        [-1.8385209 , -1.8733778 , -1.8908063 ],\n",
       "        [-1.8385209 , -1.8908063 , -1.8908063 ],\n",
       "        ...,\n",
       "        [-1.2285246 , -1.0368115 , -0.02596053],\n",
       "        [-1.1936677 , -1.0019546 ,  0.0088964 ],\n",
       "        [-1.1588107 , -0.96709764,  0.06118179]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.23510212, -0.3919583 , -0.7230991 ],\n",
       "        [-0.23510212, -0.35710138, -0.70567065],\n",
       "        [-0.21767364, -0.30481598, -0.6533853 ],\n",
       "        ...,\n",
       "        [-2.6925156 , -2.6750872 , -2.3613749 ],\n",
       "        [-2.6053734 , -2.587945  , -2.256804  ],\n",
       "        [-2.483374  , -2.4659457 , -2.1173763 ]],\n",
       "\n",
       "       [[-0.35710138, -0.51395756, -0.86252683],\n",
       "        [-0.35710138, -0.49652907, -0.8450984 ],\n",
       "        [-0.35710138, -0.46167216, -0.81024146],\n",
       "        ...,\n",
       "        [-2.6750872 , -2.6576588 , -2.3265178 ],\n",
       "        [-2.6228018 , -2.6053734 , -2.2742326 ],\n",
       "        [-2.553088  , -2.5008025 , -2.1696618 ]],\n",
       "\n",
       "       [[-0.4268152 , -0.5836714 , -0.9322407 ],\n",
       "        [-0.4442437 , -0.5836714 , -0.9322407 ],\n",
       "        [-0.4442437 , -0.5488145 , -0.91481227],\n",
       "        ...,\n",
       "        [-2.6750872 , -2.6402302 , -2.3090894 ],\n",
       "        [-2.6576588 , -2.6053734 , -2.2742326 ],\n",
       "        [-2.6053734 , -2.5356596 , -2.2045186 ]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ims[1].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(image, model):\n",
    "  c_im=model.predict_on_batch(image.reshape(1, 160, 160, 3))\n",
    "  return c_im\n",
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self, anchor, positive, y_pred):\n",
    "    super().__init__()\n",
    "    self.anchor=anchor\n",
    "    self.positive=positive\n",
    "    self.y_pred=y_pred\n",
    "  def call(self, y_pred):\n",
    "    y_pred_c=self.y_pred\n",
    "    anchor, positive = self.anchor, self.positive\n",
    "    print(y_pred.shape)\n",
    "    pos_d=tf.math.sqrt(tf.math.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=1))\n",
    "    neg_d=tf.math.sqrt(tf.math.reduce_sum(tf.square(tf.subtract(anchor, y_pred_c)), axis=1))\n",
    "    #res=tf.add(tf.subtract(neg_d, pos_d), 0.2)\n",
    "    res=tf.subtract(pos_d, neg_d)\n",
    "    res=tf.add(res, 0.3)\n",
    "    res=tf.boolean_mask(res, res>=0.2)\n",
    "    fin=tf.math.reduce_sum(res, axis=0)\n",
    "    return fin\n",
    "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "class CustomModel(tf.keras.Model):\n",
    "  def __init__(self, anchor, positive):\n",
    "    super(CustomModel, self).__init__()\n",
    "    self.anchor=anchor\n",
    "    self.positive=positive\n",
    "    self.d=tf.keras.layers.Dropout(0.8)\n",
    "    self.l_inception = self.get_inception_two()\n",
    "    self.l_1=tf.keras.layers.Conv2D(input_shape=(160, 160, 3),\n",
    "                            kernel_size=(6,6),\n",
    "                            strides=(2,2),\n",
    "                            filters=64,\n",
    "                            activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
    "    self.l_2_1=tf.keras.layers.BatchNormalization()\n",
    "    self.l_2=tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))\n",
    "    self.l_4_1=tf.keras.layers.BatchNormalization()\n",
    "    self.l_4=tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))\n",
    "    self.l_7_1=tf.keras.layers.BatchNormalization()\n",
    "    self.l_10_1=tf.keras.layers.BatchNormalization()\n",
    "    self.l_10=tf.keras.layers.AveragePooling2D(pool_size=(3,3))\n",
    "    self.l_13=tf.keras.layers.Flatten()\n",
    "    self.l_13_1=tf.keras.layers.Lambda(lambda  x: tf.math.l2_normalize(x))\n",
    "    self.l_14=tf.keras.layers.Dense(128, activation=\"sigmoid\")\n",
    "    self.l_15=tf.keras.layers.Lambda(lambda  x: tf.math.l2_normalize(x, 1, 1e-10))\n",
    "  def get_inception(self):\n",
    "    l_incept=[]\n",
    "    n=1\n",
    "    for x in range(4):\n",
    "        l=[]\n",
    "        l_4=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=64*n, activation=\"tanh\", strides=(1,1))\n",
    "        l_5=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=64*n , activation=\"tanh\", strides=(1,1))\n",
    "        l_6=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=32*n, activation=\"tanh\", strides=(1,1))\n",
    "        l_7_f=tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))\n",
    "        l_9_f=tf.keras.layers.Conv2D(kernel_size=(3,3), padding=\"same\", strides=(1,1), filters=8*n, activation=\"tanh\")\n",
    "        l_9_f_1=tf.keras.layers.Conv2D(kernel_size=(2,2), strides=(2,2), filters=64*n, activation=\"tanh\")\n",
    "        l_10_f=tf.keras.layers.Conv2D(kernel_size=(5,5), padding=\"same\", strides=(1,1), filters=8*n, activation=\"tanh\")\n",
    "        l_10_f_1=tf.keras.layers.Conv2D(kernel_size=(2,2), strides=(2,2), filters=128*n, activation=\"tanh\")\n",
    "        l.append(l_4)\n",
    "        l.append(l_5)\n",
    "        l.append(l_6)\n",
    "        l.append(l_7_f)\n",
    "        l.append(l_9_f)\n",
    "        l.append(l_9_f_1)\n",
    "        l.append(l_10_f)\n",
    "        l.append(l_10_f_1)\n",
    "        l_incept.append(l)\n",
    "        if n==2:\n",
    "            n=n+1\n",
    "        if n==4:\n",
    "            n=n+1\n",
    "        if n==6:\n",
    "            n=n+2\n",
    "        n=n+1\n",
    "    return l_incept\n",
    "  def get_inception_two(self):\n",
    "    l_incept=[]\n",
    "    n=1\n",
    "    z=0\n",
    "    c=0\n",
    "    k=2\n",
    "    for x in range(8):\n",
    "        z=z+1\n",
    "        l=[]\n",
    "        if z%2==0:\n",
    "            l_4=tf.keras.layers.Conv2D(kernel_size=(1,1), kernel_initializer=\"he_normal\", filters=32*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(1,1))\n",
    "            l_5=tf.keras.layers.Conv2D(kernel_size=(1,1), kernel_initializer=\"he_normal\", filters=32*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3),strides=(1,1))\n",
    "            l_6=tf.keras.layers.Conv2D(kernel_size=(1,1), kernel_initializer=\"he_normal\", filters=32*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(1,1))\n",
    "            l_7_f=tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding=\"same\", strides=(1,1))\n",
    "            l_9_f=tf.keras.layers.Conv2D(kernel_size=(3,3), kernel_initializer=\"he_normal\", padding=\"same\", strides=(1,1), filters=92*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
    "            l_10_f=tf.keras.layers.Conv2D(kernel_size=(5,5), kernel_initializer=\"he_normal\", padding=\"same\", strides=(1,1), filters=64*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
    "            l_11_f=tf.keras.layers.Conv2D(kernel_size=(1,1), activation=tf.keras.layers.LeakyReLU(alpha=0.3), kernel_initializer=\"he_normal\", strides=(1,1), filters=32*n)\n",
    "        else:\n",
    "            if z==7:\n",
    "                l_4=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=32*n, kernel_initializer=\"he_normal\", activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(1,1))\n",
    "                l_5=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=32*n, kernel_initializer=\"he_normal\", activation=tf.keras.layers.LeakyReLU(alpha=0.3),strides=(1,1))\n",
    "                l_6=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=32*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(1,1))\n",
    "                l_7_f=tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding=\"same\", strides=(1,1))\n",
    "                l_9_f=tf.keras.layers.Conv2D(kernel_size=(3,3), kernel_initializer=\"he_normal\", padding=\"same\", strides=(1,1), filters=92*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
    "                l_10_f=tf.keras.layers.Conv2D(kernel_size=(5,5), kernel_initializer=\"he_normal\", padding=\"same\", strides=(1,1), filters=64*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
    "                l_11_f=tf.keras.layers.Conv2D(kernel_size=(1,1), kernel_initializer=\"he_normal\", activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(1,1), filters=32*n)\n",
    "            else:\n",
    "                l_4=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=32*n, kernel_initializer=\"he_normal\", activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(1,1))\n",
    "                l_5=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=32*n, kernel_initializer=\"he_normal\", activation=tf.keras.layers.LeakyReLU(alpha=0.3),strides=(1,1))\n",
    "                l_6=tf.keras.layers.Conv2D(kernel_size=(1,1), filters=32*n, kernel_initializer=\"he_normal\", activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(1,1))\n",
    "                l_7_f=tf.keras.layers.MaxPooling2D(pool_size=(3,3), padding=\"same\", strides=(2,2))\n",
    "                l_9_f=tf.keras.layers.Conv2D(kernel_size=(3,3), padding=\"same\", kernel_initializer=\"he_normal\", strides=(2,2), filters=92*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
    "                l_10_f=tf.keras.layers.Conv2D(kernel_size=(5,5), padding=\"same\", kernel_initializer=\"he_normal\", strides=(2,2), filters=64*n, activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
    "                l_11_f=tf.keras.layers.Conv2D(kernel_size=(1,1), kernel_initializer=\"he_normal\", activation=tf.keras.layers.LeakyReLU(alpha=0.3), strides=(2,2), filters=32*n)\n",
    "        l.append(l_4)\n",
    "        l.append(l_5)\n",
    "        l.append(l_6)\n",
    "        l.append(l_7_f)\n",
    "        l.append(l_9_f)\n",
    "        l.append(l_10_f)\n",
    "        l.append(l_11_f)\n",
    "        l_incept.append(l)\n",
    "        if n%2==0:\n",
    "            c=c+1\n",
    "            if c==k:\n",
    "                n=n+1\n",
    "                c=0\n",
    "        else:\n",
    "            n=n+1\n",
    "    return l_incept\n",
    "  \n",
    "  def make_inception(self, ind, inp, training):\n",
    "    l_4=self.l_inception[ind][0](inp)\n",
    "    l_5=self.l_inception[ind][1](inp)\n",
    "    l_6=self.l_inception[ind][3](inp)\n",
    "    l_7_f=self.l_inception[ind][2](l_6)\n",
    "    l_9_f=self.l_inception[ind][4](l_4)\n",
    "    l_9_f_1=self.l_inception[ind][5](l_9_f)\n",
    "    l_10_f=self.l_inception[ind][6](l_5)\n",
    "    l_10_f_1=self.l_inception[ind][7](l_10_f)\n",
    "    l_11=tf.keras.layers.concatenate([l_7_f, l_9_f_1, l_10_f_1], axis=3)\n",
    "    return l_11\n",
    "  def make_inception_two(self, ind, inp, training):\n",
    "    l_4=self.l_inception[ind][0](inp)\n",
    "    l_5=self.l_inception[ind][1](inp)\n",
    "    l_6=self.l_inception[ind][3](inp)\n",
    "    l_7_f=self.l_inception[ind][2](l_6)\n",
    "    l_9_f=self.l_inception[ind][4](l_4)\n",
    "    l_10_f=self.l_inception[ind][5](l_5)\n",
    "    l_11_f=self.l_inception[ind][6](inp)\n",
    "    l_11=tf.keras.layers.concatenate([l_7_f, l_9_f, l_10_f, l_11_f], axis=3)\n",
    "    return l_11\n",
    "  def call(self, inputs, training=False):\n",
    "    l_1=self.l_1(inputs)\n",
    "    l_2=self.l_2(l_1)\n",
    "    l_2_1=self.l_2_1(l_2, training=training)\n",
    "    l_3=self.make_inception_two(0, l_2_1, training=training)\n",
    "    l_4_1=self.l_4_1(l_3, training=training)\n",
    "    l_4=self.l_4(l_4_1)\n",
    "    l_5=self.make_inception_two(1, l_4, training=training)\n",
    "    l_7_1=self.make_inception_two(2, l_5, training=training)\n",
    "    l_7_2=self.make_inception_two(3, l_7_1, training=training)\n",
    "    l_7=self.make_inception_two(4, l_7_2, training=training)\n",
    "    l_8=self.make_inception_two(5, l_7, training=training)\n",
    "    l_9=self.make_inception_two(6, l_8, training=training)\n",
    "    l_10=self.make_inception_two(7, l_9, training=training)\n",
    "    l_11=self.l_10(l_10)\n",
    "    l_14=self.l_13(l_11)\n",
    "    #l_15=self.l_13_1(l_14)\n",
    "    l_15=self.l_14(l_14)\n",
    "    l_f=self.l_15(l_15)\n",
    "    return l_f\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(self, data):\n",
    "    x= data\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred = self(x, training=False)\n",
    "      #y_pred = tf.divide(y_pred, tf.linalg.norm(y_pred, ord=2, keepdims=False))\n",
    "      #y_pred=tf.math.l2_normalize(y_pred)\n",
    "      anchor = self(self.anchor, training=False)\n",
    "      #anchor=tf.math.l2_normalize(anchor)\n",
    "      #anchor = tf.divide(anchor, tf.linalg.norm(anchor, ord=2, keepdims=False))\n",
    "      positive = self(self.positive[0, :, :, :, :], training=False)\n",
    "      #positive=tf.math.l2_normalize(positive)\n",
    "      #positive = tf.divide(positive, tf.linalg.norm(positive, ord=2, keepdims=False))\n",
    "      loss = CustomLoss(anchor=anchor, positive=positive, y_pred=y_pred).call(y_pred=y_pred)\n",
    "        # Compute gradients\n",
    "    trainable_vars = self.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Compute our own metrics\n",
    "    loss_tracker.update_state(loss)\n",
    "    return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "  @property\n",
    "  def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "    return [loss_tracker]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "106570240\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/50\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "3166/3166 [==============================] - 1618s 508ms/step - loss: 3.0632\n",
      "Epoch 2/50\n",
      "3166/3166 [==============================] - 1612s 509ms/step - loss: 0.1765\n",
      "Epoch 3/50\n",
      "3166/3166 [==============================] - 1754s 554ms/step - loss: 0.0782\n",
      "Epoch 4/50\n",
      "  64/3166 [..............................] - ETA: 28:41 - loss: 0.0323"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [62], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m=\u001b[39mCustomModel(anchor\u001b[38;5;241m=\u001b[39manchor\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m3\u001b[39m), positive\u001b[38;5;241m=\u001b[39ml_positive)\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mop)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"completed\")\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  print(tf.config.experimental.get_memory_usage('GPU:0'))\n",
    "op=tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.00001)\n",
    "#anchor=da.from_array(anchor)\n",
    "#positive=da.from_array(positive)\n",
    "model=CustomModel(anchor=anchor.reshape(1,160, 160, 3), positive=l_positive)\n",
    "model.compile(optimizer=op)\n",
    "model.fit(epochs=50, x=ims, batch_size=64, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9317637383937836\n",
      "0.5190076678991318\n",
      "success\n",
      "0.5203875750303268\n",
      "success\n",
      "0.7376421242952347\n",
      "unable\n",
      "0.8453105092048645\n",
      "unable\n",
      "0.8434496819972992\n",
      "unable\n",
      "0.8748961687088013\n",
      "unable\n",
      "0.8350441753864288\n",
      "unable\n",
      "0.7839521169662476\n",
      "unable\n",
      "0.7839521169662476\n",
      "unable\n",
      "0.8330322504043579\n",
      "unable\n",
      "0.8330322504043579\n",
      "unable\n",
      "0.867167204618454\n",
      "unable\n",
      "0.8434445858001709\n",
      "unable\n",
      "0.9285751283168793\n",
      "unable\n",
      "0.9362369477748871\n",
      "unable\n",
      "0.824607789516449\n",
      "unable\n",
      "0.6549215465784073\n",
      "unable\n",
      "0.7135917395353317\n",
      "unable\n",
      "0.8269849419593811\n",
      "unable\n",
      "0.6825893819332123\n",
      "unable\n",
      "0.8747428357601166\n",
      "unable\n",
      "0.649031326174736\n",
      "unable\n",
      "0.6602391600608826\n",
      "unable\n",
      "0.6996773779392242\n",
      "unable\n",
      "0.6604379564523697\n",
      "unable\n",
      "0.6524176597595215\n",
      "unable\n",
      "0.6069089770317078\n",
      "unable\n",
      "0.5870680510997772\n",
      "success\n",
      "0.6030549556016922\n",
      "unable\n",
      "0.6401406079530716\n",
      "unable\n",
      "0.8755980134010315\n",
      "unable\n",
      "0.606020450592041\n",
      "unable\n",
      "0.6097663789987564\n",
      "unable\n",
      "0.5951078832149506\n",
      "success\n",
      "0.5951078832149506\n",
      "success\n",
      "0.5990273058414459\n",
      "success\n",
      "0.6169010996818542\n",
      "unable\n",
      "0.5876056551933289\n",
      "success\n",
      "0.5779860466718674\n",
      "success\n",
      "0.5713999271392822\n",
      "success\n",
      "0.5713999271392822\n",
      "success\n",
      "0.5509584993124008\n",
      "success\n",
      "0.6133416295051575\n",
      "unable\n",
      "0.6104898154735565\n",
      "unable\n",
      "0.6028473973274231\n",
      "unable\n",
      "0.6020806431770325\n",
      "unable\n",
      "0.5705497562885284\n",
      "success\n",
      "0.5577723383903503\n",
      "success\n",
      "0.6208400577306747\n",
      "unable\n",
      "0.5653040707111359\n",
      "success\n",
      "0.7868431806564331\n",
      "unable\n",
      "0.5615611374378204\n",
      "success\n",
      "0.5843289792537689\n",
      "success\n",
      "0.5374253243207932\n",
      "success\n",
      "0.5963213592767715\n",
      "success\n",
      "0.7386401295661926\n",
      "unable\n",
      "0.5524066686630249\n",
      "success\n",
      "0.7333013266324997\n",
      "unable\n",
      "0.5946532487869263\n",
      "success\n",
      "0.5312122106552124\n",
      "success\n",
      "0.7136717587709427\n",
      "unable\n",
      "0.5547722429037094\n",
      "success\n",
      "0.5231388956308365\n",
      "success\n",
      "0.6534800380468369\n",
      "unable\n",
      "0.5309055000543594\n",
      "success\n",
      "0.6483579128980637\n",
      "unable\n",
      "0.7316556572914124\n",
      "unable\n",
      "0.5841418951749802\n",
      "success\n",
      "0.5849942117929459\n",
      "success\n",
      "0.6166379302740097\n",
      "unable\n",
      "0.5802137106657028\n",
      "success\n",
      "0.573584720492363\n",
      "success\n",
      "0.5844924598932266\n",
      "success\n",
      "0.6744986325502396\n",
      "unable\n",
      "0.6785250753164291\n",
      "unable\n",
      "0.6433807164430618\n",
      "unable\n",
      "0.6638560742139816\n",
      "unable\n",
      "0.7096138447523117\n",
      "unable\n",
      "0.7069015502929688\n",
      "unable\n",
      "0.6841652691364288\n",
      "unable\n",
      "0.7245433777570724\n",
      "unable\n",
      "0.6387923508882523\n",
      "unable\n",
      "0.663724958896637\n",
      "unable\n",
      "0.6445526629686356\n",
      "unable\n",
      "0.6631312519311905\n",
      "unable\n",
      "0.6727483123540878\n",
      "unable\n",
      "0.6719672083854675\n",
      "unable\n",
      "0.6404127180576324\n",
      "unable\n",
      "0.6443990617990494\n",
      "unable\n",
      "0.6438074111938477\n",
      "unable\n",
      "0.6818912923336029\n",
      "unable\n",
      "0.9167279899120331\n",
      "unable\n",
      "0.6444352716207504\n",
      "unable\n",
      "0.6387899369001389\n",
      "unable\n",
      "0.6266485154628754\n",
      "unable\n",
      "0.6666563004255295\n",
      "unable\n",
      "0.6343768537044525\n",
      "unable\n",
      "0.6294309496879578\n",
      "unable\n",
      "0.6517074555158615\n",
      "unable\n",
      "0.6999120712280273\n",
      "unable\n",
      "0.6438286900520325\n",
      "unable\n",
      "0.7137562483549118\n",
      "unable\n",
      "0.6660090833902359\n",
      "unable\n",
      "0.6670045405626297\n",
      "unable\n",
      "0.6654532849788666\n",
      "unable\n",
      "0.7062774896621704\n",
      "unable\n",
      "0.6922638416290283\n",
      "unable\n",
      "0.7373224496841431\n",
      "unable\n",
      "0.7308916747570038\n",
      "unable\n",
      "0.685837984085083\n",
      "unable\n",
      "0.7208748310804367\n",
      "unable\n",
      "0.6904242038726807\n",
      "unable\n",
      "0.7197076231241226\n",
      "unable\n",
      "0.7056085020303726\n",
      "unable\n",
      "0.6927085071802139\n",
      "unable\n",
      "0.7086244225502014\n",
      "unable\n",
      "0.7112977355718613\n",
      "unable\n",
      "0.6818400174379349\n",
      "unable\n",
      "0.6820109635591507\n",
      "unable\n",
      "0.6850235313177109\n",
      "unable\n",
      "0.6977801620960236\n",
      "unable\n",
      "0.7009583115577698\n",
      "unable\n",
      "0.7020436674356461\n",
      "unable\n",
      "0.690958634018898\n",
      "unable\n",
      "0.7340336591005325\n",
      "unable\n",
      "0.650881290435791\n",
      "unable\n",
      "0.6404676139354706\n",
      "unable\n",
      "0.6741702854633331\n",
      "unable\n",
      "0.6933200061321259\n",
      "unable\n",
      "0.6841895431280136\n",
      "unable\n",
      "0.6722578257322311\n",
      "unable\n",
      "0.7372371554374695\n",
      "unable\n",
      "0.7025748789310455\n",
      "unable\n",
      "0.7376857548952103\n",
      "unable\n",
      "0.7027085423469543\n",
      "unable\n",
      "0.7234117090702057\n",
      "unable\n",
      "0.721649095416069\n",
      "unable\n",
      "0.7302147746086121\n",
      "unable\n",
      "0.7306176424026489\n",
      "unable\n",
      "0.7247937619686127\n",
      "unable\n",
      "0.7002887427806854\n",
      "unable\n",
      "0.6865086704492569\n",
      "unable\n",
      "0.662460520863533\n",
      "unable\n",
      "0.7235755026340485\n",
      "unable\n",
      "0.6736391186714172\n",
      "unable\n",
      "0.6642995774745941\n",
      "unable\n",
      "0.6936409771442413\n",
      "unable\n",
      "0.6895626783370972\n",
      "unable\n",
      "0.7469847947359085\n",
      "unable\n",
      "0.7397678196430206\n",
      "unable\n",
      "0.7230590432882309\n",
      "unable\n",
      "0.6968153268098831\n",
      "unable\n",
      "0.6945774257183075\n",
      "unable\n",
      "0.6621722728013992\n",
      "unable\n",
      "0.6710309386253357\n",
      "unable\n",
      "0.6753805428743362\n",
      "unable\n",
      "0.6481204479932785\n",
      "unable\n",
      "0.679159551858902\n",
      "unable\n",
      "0.6891671866178513\n",
      "unable\n",
      "0.6498401463031769\n",
      "unable\n",
      "0.6891392916440964\n",
      "unable\n",
      "0.6949354559183121\n",
      "unable\n",
      "0.7348888367414474\n",
      "unable\n",
      "0.6779808104038239\n",
      "unable\n",
      "0.6277377158403397\n",
      "unable\n",
      "0.5904977917671204\n",
      "success\n",
      "0.602160707116127\n",
      "unable\n",
      "0.6564579606056213\n",
      "unable\n",
      "0.6316539645195007\n",
      "unable\n",
      "0.5619642287492752\n",
      "success\n",
      "0.5612099915742874\n",
      "success\n",
      "0.5640644431114197\n",
      "success\n",
      "0.5229870826005936\n",
      "success\n",
      "0.5474517792463303\n",
      "success\n",
      "0.5890586078166962\n",
      "success\n",
      "0.6069910526275635\n",
      "unable\n",
      "0.5438603907823563\n",
      "success\n",
      "0.5296113789081573\n",
      "success\n",
      "0.5590375363826752\n",
      "success\n",
      "0.6045522093772888\n",
      "unable\n",
      "0.6332640945911407\n",
      "unable\n",
      "0.6380968540906906\n",
      "unable\n",
      "0.6382736563682556\n",
      "unable\n",
      "0.6533869206905365\n",
      "unable\n",
      "0.6213151216506958\n",
      "unable\n",
      "0.5969013422727585\n",
      "success\n",
      "0.6404204070568085\n",
      "unable\n",
      "0.5851125866174698\n",
      "success\n",
      "0.5991976261138916\n",
      "success\n",
      "0.5997394770383835\n",
      "success\n",
      "0.5746765583753586\n",
      "success\n",
      "0.5570030361413956\n",
      "success\n",
      "0.56378173828125\n",
      "success\n",
      "0.6767389476299286\n",
      "unable\n",
      "0.5992500633001328\n",
      "success\n",
      "0.5969455540180206\n",
      "success\n",
      "0.5905002951622009\n",
      "success\n",
      "0.5966564565896988\n",
      "success\n",
      "0.6365847140550613\n",
      "unable\n",
      "0.6445038467645645\n",
      "unable\n",
      "0.696582019329071\n",
      "unable\n",
      "0.7122330665588379\n",
      "unable\n",
      "0.7381003350019455\n",
      "unable\n",
      "0.7895164489746094\n",
      "unable\n",
      "0.7171415984630585\n",
      "unable\n",
      "0.7708725035190582\n",
      "unable\n",
      "0.7951844036579132\n",
      "unable\n",
      "0.8218845427036285\n",
      "unable\n",
      "0.8586914241313934\n",
      "unable\n",
      "0.872043639421463\n",
      "unable\n",
      "0.8064769506454468\n",
      "unable\n",
      "0.8552820682525635\n",
      "unable\n",
      "0.851951390504837\n",
      "unable\n",
      "0.8803995251655579\n",
      "unable\n",
      "0.8481679558753967\n",
      "unable\n",
      "0.8562597334384918\n",
      "unable\n",
      "0.8547420501708984\n",
      "unable\n",
      "0.8463171422481537\n",
      "unable\n",
      "0.8271540999412537\n",
      "unable\n",
      "0.8393355309963226\n",
      "unable\n",
      "0.8430650532245636\n",
      "unable\n",
      "0.8511357307434082\n",
      "unable\n",
      "0.7902573645114899\n",
      "unable\n",
      "0.7199211716651917\n",
      "unable\n",
      "0.6646049469709396\n",
      "unable\n",
      "0.6520655304193497\n",
      "unable\n",
      "0.6498072892427444\n",
      "unable\n",
      "0.6799955517053604\n",
      "unable\n",
      "0.6774892508983612\n",
      "unable\n",
      "0.6908096820116043\n",
      "unable\n",
      "0.6908096820116043\n",
      "unable\n",
      "0.6931064128875732\n",
      "unable\n",
      "0.6810845285654068\n",
      "unable\n",
      "0.6692744493484497\n",
      "unable\n",
      "0.6611199527978897\n",
      "unable\n",
      "0.6767840534448624\n",
      "unable\n",
      "0.7834373116493225\n",
      "unable\n",
      "0.7901355922222137\n",
      "unable\n",
      "0.7930063605308533\n",
      "unable\n",
      "0.7534326016902924\n",
      "unable\n",
      "0.7969540357589722\n",
      "unable\n",
      "0.7817578017711639\n",
      "unable\n",
      "0.7979138195514679\n",
      "unable\n",
      "0.7749835252761841\n",
      "unable\n",
      "0.764328271150589\n",
      "unable\n",
      "0.8181918561458588\n",
      "unable\n",
      "0.8256000280380249\n",
      "unable\n",
      "0.8105566799640656\n",
      "unable\n",
      "0.8232373595237732\n",
      "unable\n",
      "0.7955503463745117\n",
      "unable\n",
      "0.8381728827953339\n",
      "unable\n",
      "0.7873837351799011\n",
      "unable\n",
      "0.8133323192596436\n",
      "unable\n",
      "0.7608926296234131\n",
      "unable\n",
      "0.7582197189331055\n",
      "unable\n",
      "0.7470542192459106\n",
      "unable\n",
      "0.7442261427640915\n",
      "unable\n",
      "0.7447091192007065\n",
      "unable\n",
      "0.767511785030365\n",
      "unable\n",
      "0.7340742945671082\n",
      "unable\n",
      "0.7834289968013763\n",
      "unable\n",
      "0.7900310754776001\n",
      "unable\n",
      "0.7454285770654678\n",
      "unable\n",
      "0.7914503216743469\n",
      "unable\n",
      "0.7806640863418579\n",
      "unable\n",
      "0.780541330575943\n",
      "unable\n",
      "0.6937428563833237\n",
      "unable\n",
      "0.7422438561916351\n",
      "unable\n",
      "0.7868000864982605\n",
      "unable\n",
      "0.7700121402740479\n",
      "unable\n",
      "0.7700121402740479\n",
      "unable\n",
      "0.7848329544067383\n",
      "unable\n",
      "0.7913884520530701\n",
      "unable\n",
      "0.7266506999731064\n",
      "unable\n",
      "0.7234003990888596\n",
      "unable\n",
      "0.6847983151674271\n",
      "unable\n",
      "0.6582385003566742\n",
      "unable\n",
      "0.6526583433151245\n",
      "unable\n",
      "0.6391067951917648\n",
      "unable\n",
      "0.6116246581077576\n",
      "unable\n",
      "0.6213863343000412\n",
      "unable\n",
      "0.5924954116344452\n",
      "success\n",
      "0.6712642461061478\n",
      "unable\n",
      "0.6457843780517578\n",
      "unable\n",
      "0.6350515633821487\n",
      "unable\n",
      "0.6253677159547806\n",
      "unable\n",
      "0.609991192817688\n",
      "unable\n",
      "0.6290043443441391\n",
      "unable\n",
      "0.5702225267887115\n",
      "success\n",
      "0.6181360334157944\n",
      "unable\n",
      "0.5907163918018341\n",
      "success\n",
      "0.6773561239242554\n",
      "unable\n",
      "0.6465784460306168\n",
      "unable\n",
      "0.6229813098907471\n",
      "unable\n",
      "0.5818695724010468\n",
      "success\n",
      "0.5800335109233856\n",
      "success\n",
      "0.6494224369525909\n",
      "unable\n",
      "0.5791636258363724\n",
      "success\n",
      "0.6066592633724213\n",
      "unable\n",
      "0.5751628875732422\n",
      "success\n",
      "0.5688294768333435\n",
      "success\n",
      "0.5861591398715973\n",
      "success\n",
      "0.6243968904018402\n",
      "unable\n",
      "0.6248426288366318\n",
      "unable\n",
      "0.613124281167984\n",
      "unable\n",
      "0.6124057173728943\n",
      "unable\n",
      "0.6153944134712219\n",
      "unable\n",
      "0.6341009438037872\n",
      "unable\n",
      "0.6533478051424026\n",
      "unable\n",
      "0.666770875453949\n",
      "unable\n",
      "0.6247717291116714\n",
      "unable\n",
      "0.6079347878694534\n",
      "unable\n",
      "0.6640604585409164\n",
      "unable\n",
      "0.6417424231767654\n",
      "unable\n",
      "0.640586256980896\n",
      "unable\n",
      "0.649356409907341\n",
      "unable\n",
      "0.6443373709917068\n",
      "unable\n",
      "0.6037937253713608\n",
      "unable\n",
      "0.6595398634672165\n",
      "unable\n",
      "0.6678841263055801\n",
      "unable\n",
      "0.6044725030660629\n",
      "unable\n",
      "0.5995354056358337\n",
      "success\n",
      "0.6256712079048157\n",
      "unable\n",
      "0.6459929198026657\n",
      "unable\n",
      "0.5841468125581741\n",
      "success\n",
      "0.6382383406162262\n",
      "unable\n",
      "0.5984990894794464\n",
      "success\n",
      "0.5701094716787338\n",
      "success\n",
      "0.5799607336521149\n",
      "success\n",
      "0.5317159742116928\n",
      "success\n",
      "0.5589372217655182\n",
      "success\n",
      "0.5795293897390366\n",
      "success\n",
      "0.5869539231061935\n",
      "success\n",
      "0.569862887263298\n",
      "success\n",
      "0.5856956541538239\n",
      "success\n",
      "0.5553478896617889\n",
      "success\n",
      "0.563890814781189\n",
      "success\n",
      "0.5685428828001022\n",
      "success\n",
      "0.5892523974180222\n",
      "success\n",
      "0.5615418702363968\n",
      "success\n",
      "0.5626178830862045\n",
      "success\n",
      "0.5880657434463501\n",
      "success\n",
      "0.5665652453899384\n",
      "success\n",
      "0.6035997569561005\n",
      "unable\n",
      "0.5698705762624741\n",
      "success\n",
      "0.5631487816572189\n",
      "success\n",
      "0.5992657989263535\n",
      "success\n",
      "0.5900604128837585\n",
      "success\n",
      "0.6110398918390274\n",
      "unable\n",
      "0.6079460084438324\n",
      "unable\n",
      "0.5800352990627289\n",
      "success\n",
      "0.5869737267494202\n",
      "success\n",
      "0.5880648493766785\n",
      "success\n",
      "0.6049107313156128\n",
      "unable\n",
      "0.5878371298313141\n",
      "success\n",
      "0.6039086580276489\n",
      "unable\n",
      "0.6018612384796143\n",
      "unable\n",
      "0.6041632890701294\n",
      "unable\n",
      "0.5932711064815521\n",
      "success\n",
      "0.5871912091970444\n",
      "success\n",
      "0.6317465454339981\n",
      "unable\n",
      "0.5489206463098526\n",
      "success\n",
      "0.5786074697971344\n",
      "success\n",
      "0.563033401966095\n",
      "success\n",
      "0.5671605616807938\n",
      "success\n",
      "0.6150442510843277\n",
      "unable\n",
      "0.6094043701887131\n",
      "unable\n",
      "0.5596972703933716\n",
      "success\n",
      "0.5948310792446136\n",
      "success\n",
      "0.5814079195261002\n",
      "success\n",
      "0.5959081649780273\n",
      "success\n",
      "0.6101842671632767\n",
      "unable\n",
      "0.6046894937753677\n",
      "unable\n",
      "0.6171925663948059\n",
      "unable\n",
      "0.6241550445556641\n",
      "unable\n",
      "0.6227281987667084\n",
      "unable\n",
      "0.5931777209043503\n",
      "success\n",
      "0.5946630388498306\n",
      "success\n",
      "0.5882382094860077\n",
      "success\n",
      "0.5835851579904556\n",
      "success\n",
      "0.5972395241260529\n",
      "success\n",
      "0.5759560167789459\n",
      "success\n",
      "0.5678116232156754\n",
      "success\n",
      "0.6122721433639526\n",
      "unable\n",
      "0.5710181146860123\n",
      "success\n",
      "0.5367545932531357\n",
      "success\n",
      "0.5367545932531357\n",
      "success\n",
      "0.618074968457222\n",
      "unable\n",
      "0.5751765221357346\n",
      "success\n",
      "0.5637010931968689\n",
      "success\n",
      "0.5910649001598358\n",
      "success\n",
      "0.5565747767686844\n",
      "success\n",
      "0.5719499588012695\n",
      "success\n",
      "0.5679217278957367\n",
      "success\n",
      "0.6108938902616501\n",
      "unable\n",
      "0.6209650039672852\n",
      "unable\n",
      "0.5923718065023422\n",
      "success\n",
      "0.6294845938682556\n",
      "unable\n",
      "0.6135357767343521\n",
      "unable\n",
      "0.6174949407577515\n",
      "unable\n",
      "0.6100237816572189\n",
      "unable\n",
      "0.6235527098178864\n",
      "unable\n",
      "0.6393178403377533\n",
      "unable\n",
      "0.6278035193681717\n",
      "unable\n",
      "0.6206206977367401\n",
      "unable\n",
      "0.636696070432663\n",
      "unable\n",
      "0.6023878008127213\n",
      "unable\n",
      "0.6002523601055145\n",
      "unable\n",
      "0.5850143730640411\n",
      "success\n",
      "0.6054111868143082\n",
      "unable\n",
      "0.5963397324085236\n",
      "success\n",
      "0.5864369720220566\n",
      "success\n",
      "0.5818865150213242\n",
      "success\n",
      "0.5897343456745148\n",
      "success\n",
      "0.5892308056354523\n",
      "success\n",
      "0.5901171416044235\n",
      "success\n",
      "0.780037522315979\n",
      "unable\n",
      "0.803742527961731\n",
      "unable\n",
      "0.8334289491176605\n",
      "unable\n",
      "0.7872286140918732\n",
      "unable\n",
      "0.7680521607398987\n",
      "unable\n",
      "0.7440266311168671\n",
      "unable\n",
      "0.7244254052639008\n",
      "unable\n",
      "0.5036275684833527\n",
      "success\n",
      "0.4742337763309479\n",
      "success\n",
      "0.55548195540905\n",
      "success\n",
      "0.5806278437376022\n",
      "success\n",
      "0.5581369400024414\n",
      "success\n",
      "0.5362652689218521\n",
      "success\n",
      "0.598297655582428\n",
      "success\n",
      "0.583764910697937\n",
      "success\n",
      "0.537753626704216\n",
      "success\n",
      "0.5584758371114731\n",
      "success\n",
      "0.563195675611496\n",
      "success\n",
      "0.5885032117366791\n",
      "success\n",
      "0.5646362900733948\n",
      "success\n",
      "0.5727348625659943\n",
      "success\n",
      "0.581964299082756\n",
      "success\n",
      "0.5498152077198029\n",
      "success\n",
      "0.5826197862625122\n",
      "success\n",
      "0.5854204148054123\n",
      "success\n",
      "0.5510809868574142\n",
      "success\n",
      "0.5501624196767807\n",
      "success\n",
      "0.521288126707077\n",
      "success\n",
      "0.5702873468399048\n",
      "success\n",
      "0.5208197236061096\n",
      "success\n",
      "0.5497198104858398\n",
      "success\n",
      "0.5267356038093567\n",
      "success\n",
      "0.5142568498849869\n",
      "success\n",
      "0.5428857207298279\n",
      "success\n",
      "0.5312694758176804\n",
      "success\n",
      "0.5124628990888596\n",
      "success\n",
      "0.5775991380214691\n",
      "success\n",
      "0.9452813565731049\n",
      "unable\n",
      "0.641880601644516\n",
      "unable\n",
      "0.641880601644516\n",
      "unable\n",
      "0.6147172451019287\n",
      "unable\n",
      "0.6147172451019287\n",
      "unable\n",
      "0.5630127042531967\n",
      "success\n",
      "0.5443407744169235\n",
      "success\n",
      "0.5701235085725784\n",
      "success\n",
      "0.5681343376636505\n",
      "success\n",
      "0.5619159489870071\n",
      "success\n",
      "0.5281193554401398\n",
      "success\n",
      "0.5355190336704254\n",
      "success\n",
      "0.5661957710981369\n",
      "success\n",
      "0.5392450243234634\n",
      "success\n",
      "0.5563041865825653\n",
      "success\n",
      "0.5984849184751511\n",
      "success\n",
      "0.6072574406862259\n",
      "unable\n",
      "0.609763965010643\n",
      "unable\n",
      "0.5571613758802414\n",
      "success\n",
      "0.5720563977956772\n",
      "success\n",
      "0.6206104606389999\n",
      "unable\n",
      "0.601742684841156\n",
      "unable\n",
      "0.6079608500003815\n",
      "unable\n",
      "0.6057524532079697\n",
      "unable\n",
      "0.5583847314119339\n",
      "success\n",
      "0.5280349105596542\n",
      "success\n",
      "0.534090980887413\n",
      "success\n",
      "0.577513575553894\n",
      "success\n",
      "0.5414253920316696\n",
      "success\n",
      "0.5624805092811584\n",
      "success\n",
      "0.5544944554567337\n",
      "success\n",
      "0.571826845407486\n",
      "success\n",
      "0.5693705230951309\n",
      "success\n",
      "0.5722412467002869\n",
      "success\n",
      "0.530164048075676\n",
      "success\n",
      "0.5203558802604675\n",
      "success\n",
      "0.5113978385925293\n",
      "success\n",
      "0.5255380868911743\n",
      "success\n",
      "0.4882800579071045\n",
      "success\n",
      "0.5613806247711182\n",
      "success\n",
      "0.5613806247711182\n",
      "success\n",
      "0.5301066488027573\n",
      "success\n",
      "0.518802747130394\n",
      "success\n",
      "0.4986221641302109\n",
      "success\n",
      "0.44419388473033905\n",
      "success\n",
      "0.45686937868595123\n",
      "success\n",
      "0.4975094050168991\n",
      "success\n",
      "0.49315372109413147\n",
      "success\n",
      "0.49631886184215546\n",
      "success\n",
      "0.4526483416557312\n",
      "success\n",
      "0.4948264807462692\n",
      "success\n",
      "0.5117662400007248\n",
      "success\n",
      "0.5589096397161484\n",
      "success\n",
      "0.5638498663902283\n",
      "success\n",
      "0.6214130222797394\n",
      "unable\n",
      "0.5538806766271591\n",
      "success\n",
      "0.5492799282073975\n",
      "success\n",
      "0.6074923574924469\n",
      "unable\n",
      "0.577807679772377\n",
      "success\n",
      "0.5935991406440735\n",
      "success\n",
      "0.5882950276136398\n",
      "success\n",
      "0.546750470995903\n",
      "success\n",
      "0.543181300163269\n",
      "success\n",
      "0.5590926110744476\n",
      "success\n",
      "0.6031816452741623\n",
      "unable\n",
      "0.599548950791359\n",
      "success\n",
      "0.5937717854976654\n",
      "success\n",
      "0.5413128286600113\n",
      "success\n",
      "0.5745896995067596\n",
      "success\n",
      "0.5701805502176285\n",
      "success\n",
      "0.5736588835716248\n",
      "success\n",
      "0.557465448975563\n",
      "success\n",
      "0.5548882484436035\n",
      "success\n",
      "0.5977960377931595\n",
      "success\n",
      "0.5240264385938644\n",
      "success\n",
      "0.5589363723993301\n",
      "success\n",
      "0.5510428994894028\n",
      "success\n",
      "0.5480844229459763\n",
      "success\n",
      "0.5411467552185059\n",
      "success\n",
      "0.5615764707326889\n",
      "success\n",
      "0.5279010236263275\n",
      "success\n",
      "0.6350005567073822\n",
      "unable\n",
      "0.5398546904325485\n",
      "success\n",
      "0.579700157046318\n",
      "success\n",
      "0.606926366686821\n",
      "unable\n",
      "0.5814697444438934\n",
      "success\n",
      "0.580009326338768\n",
      "success\n",
      "0.555380791425705\n",
      "success\n",
      "0.555380791425705\n",
      "success\n",
      "0.5959851443767548\n",
      "success\n",
      "0.5849324762821198\n",
      "success\n",
      "0.5848620235919952\n",
      "success\n",
      "0.6336552500724792\n",
      "unable\n",
      "0.6303835362195969\n",
      "unable\n",
      "0.5975486487150192\n",
      "success\n",
      "0.5785504728555679\n",
      "success\n",
      "0.6291186958551407\n",
      "unable\n",
      "0.6322583109140396\n",
      "unable\n",
      "0.6493645906448364\n",
      "unable\n",
      "0.6601644605398178\n",
      "unable\n",
      "0.6804492920637131\n",
      "unable\n",
      "0.5955198258161545\n",
      "success\n",
      "0.6218465566635132\n",
      "unable\n",
      "0.6262772530317307\n",
      "unable\n",
      "0.6069518029689789\n",
      "unable\n",
      "0.6752590835094452\n",
      "unable\n",
      "0.6648061126470566\n",
      "unable\n",
      "0.7030928134918213\n",
      "unable\n",
      "0.6562967151403427\n",
      "unable\n",
      "0.5743241161108017\n",
      "success\n",
      "0.6141396760940552\n",
      "unable\n",
      "0.7029321491718292\n",
      "unable\n",
      "0.7221148163080215\n",
      "unable\n",
      "0.7136087715625763\n",
      "unable\n",
      "0.7596905529499054\n",
      "unable\n",
      "0.7130708992481232\n",
      "unable\n",
      "0.7083195894956589\n",
      "unable\n",
      "0.7206975817680359\n",
      "unable\n",
      "0.7442368716001511\n",
      "unable\n",
      "0.7340265065431595\n",
      "unable\n",
      "0.6883275210857391\n",
      "unable\n",
      "0.6949006766080856\n",
      "unable\n",
      "0.6851519197225571\n",
      "unable\n",
      "0.706611692905426\n",
      "unable\n",
      "0.7226552367210388\n",
      "unable\n",
      "0.703481063246727\n",
      "unable\n",
      "0.7283545285463333\n",
      "unable\n",
      "0.7494843900203705\n",
      "unable\n",
      "0.7396963387727737\n",
      "unable\n",
      "0.7395327687263489\n",
      "unable\n",
      "0.7491043210029602\n",
      "unable\n",
      "0.708660900592804\n",
      "unable\n",
      "0.7685065269470215\n",
      "unable\n",
      "0.7700212597846985\n",
      "unable\n",
      "0.7312527000904083\n",
      "unable\n",
      "0.7545801401138306\n",
      "unable\n",
      "0.7365705370903015\n",
      "unable\n",
      "0.7464710623025894\n",
      "unable\n",
      "0.7483740895986557\n",
      "unable\n",
      "0.7285314649343491\n",
      "unable\n",
      "0.7858955562114716\n",
      "unable\n",
      "0.8050729036331177\n",
      "unable\n",
      "0.8445225656032562\n",
      "unable\n",
      "0.790475606918335\n",
      "unable\n",
      "0.7642215192317963\n",
      "unable\n",
      "0.7388573437929153\n",
      "unable\n",
      "0.6809320896863937\n",
      "unable\n",
      "0.6349203586578369\n",
      "unable\n",
      "0.6967004835605621\n",
      "unable\n",
      "0.7228446006774902\n",
      "unable\n",
      "0.71278215944767\n",
      "unable\n",
      "0.7074338346719742\n",
      "unable\n",
      "0.7381289899349213\n",
      "unable\n",
      "0.7135674208402634\n",
      "unable\n",
      "0.7314179241657257\n",
      "unable\n",
      "0.7299273312091827\n",
      "unable\n",
      "0.6885171979665756\n",
      "unable\n",
      "0.7052620500326157\n",
      "unable\n",
      "0.6982811987400055\n",
      "unable\n",
      "0.7381256371736526\n",
      "unable\n",
      "0.7243421673774719\n",
      "unable\n",
      "0.7417165786027908\n",
      "unable\n",
      "0.7404107004404068\n",
      "unable\n",
      "0.6948394775390625\n",
      "unable\n",
      "0.6928783357143402\n",
      "unable\n",
      "0.6831148266792297\n",
      "unable\n",
      "0.7240322381258011\n",
      "unable\n",
      "0.7005207538604736\n",
      "unable\n",
      "0.7087928205728531\n",
      "unable\n",
      "0.7408237606287003\n",
      "unable\n",
      "0.6992819309234619\n",
      "unable\n",
      "0.7518848776817322\n",
      "unable\n",
      "0.6491885930299759\n",
      "unable\n",
      "0.7262099236249924\n",
      "unable\n",
      "0.7369655817747116\n",
      "unable\n",
      "0.7405260801315308\n",
      "unable\n",
      "0.7427220940589905\n",
      "unable\n",
      "0.7793573141098022\n",
      "unable\n",
      "0.7245533913373947\n",
      "unable\n",
      "0.7345876693725586\n",
      "unable\n",
      "0.7180494368076324\n",
      "unable\n",
      "0.769460141658783\n",
      "unable\n",
      "0.7650646269321442\n",
      "unable\n",
      "0.7205609232187271\n",
      "unable\n",
      "0.7852992117404938\n",
      "unable\n",
      "0.7509438693523407\n",
      "unable\n",
      "0.7576488554477692\n",
      "unable\n",
      "0.7480011284351349\n",
      "unable\n",
      "0.6962070018053055\n",
      "unable\n",
      "0.7365624010562897\n",
      "unable\n",
      "0.7476686239242554\n",
      "unable\n",
      "0.699309915304184\n",
      "unable\n",
      "0.661846473813057\n",
      "unable\n",
      "0.6261516362428665\n",
      "unable\n",
      "0.5870745331048965\n",
      "success\n",
      "0.6044735312461853\n",
      "unable\n",
      "0.56605164706707\n",
      "success\n",
      "0.5641274303197861\n",
      "success\n",
      "0.556857168674469\n",
      "success\n",
      "0.5407643616199493\n",
      "success\n",
      "0.5528790503740311\n",
      "success\n",
      "0.527117058634758\n",
      "success\n",
      "0.5361048728227615\n",
      "success\n",
      "0.5120365172624588\n",
      "success\n",
      "0.5298992693424225\n",
      "success\n",
      "0.556007131934166\n",
      "success\n",
      "0.5403196960687637\n",
      "success\n",
      "0.559443399310112\n",
      "success\n",
      "0.5755008459091187\n",
      "success\n",
      "0.5703768879175186\n",
      "success\n",
      "0.520351767539978\n",
      "success\n",
      "0.5021255761384964\n",
      "success\n",
      "0.5130533427000046\n",
      "success\n",
      "0.5434315949678421\n",
      "success\n",
      "0.5001274198293686\n",
      "success\n",
      "0.5152236074209213\n",
      "success\n",
      "0.5171606093645096\n",
      "success\n",
      "0.5171995013952255\n",
      "success\n",
      "0.5902947932481766\n",
      "success\n",
      "0.5673895329236984\n",
      "success\n",
      "0.6151574850082397\n",
      "unable\n",
      "0.6004663556814194\n",
      "unable\n",
      "0.5877791494131088\n",
      "success\n",
      "0.5413317382335663\n",
      "success\n",
      "0.5385880619287491\n",
      "success\n",
      "0.5498676002025604\n",
      "success\n",
      "0.5667538046836853\n",
      "success\n",
      "0.5944283902645111\n",
      "success\n",
      "0.6083776652812958\n",
      "unable\n",
      "0.5854647606611252\n",
      "success\n",
      "0.5535397678613663\n",
      "success\n",
      "0.6130361706018448\n",
      "unable\n",
      "0.5879328846931458\n",
      "success\n",
      "0.5774862617254257\n",
      "success\n",
      "0.585356667637825\n",
      "success\n",
      "0.5829326659440994\n",
      "success\n",
      "0.5394890606403351\n",
      "success\n",
      "0.5352758020162582\n",
      "success\n",
      "0.5568619966506958\n",
      "success\n",
      "0.5751333385705948\n",
      "success\n",
      "0.5702157765626907\n",
      "success\n",
      "0.5514233708381653\n",
      "success\n",
      "0.5774095505475998\n",
      "success\n",
      "0.5860789865255356\n",
      "success\n",
      "0.6115084290504456\n",
      "unable\n",
      "0.5794600546360016\n",
      "success\n",
      "0.5659722089767456\n",
      "success\n",
      "0.5493868142366409\n",
      "success\n",
      "0.5627005398273468\n",
      "success\n",
      "0.5490978509187698\n",
      "success\n",
      "0.5731597244739532\n",
      "success\n",
      "0.5563602447509766\n",
      "success\n",
      "0.5520665198564529\n",
      "success\n",
      "0.5159483402967453\n",
      "success\n",
      "0.565766841173172\n",
      "success\n",
      "0.5597398728132248\n",
      "success\n",
      "0.5355030298233032\n",
      "success\n",
      "0.5362447053194046\n",
      "success\n",
      "0.6450508385896683\n",
      "unable\n",
      "0.628944531083107\n",
      "unable\n",
      "0.6303665935993195\n",
      "unable\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [74], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m im_\u001b[38;5;241m=\u001b[39mim_\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     29\u001b[0m im_\u001b[38;5;241m=\u001b[39m(im_\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(im_))\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mstd(im_)\n\u001b[1;32m---> 30\u001b[0m f_d\u001b[38;5;241m=\u001b[39m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m pos\u001b[38;5;241m=\u001b[39mconvert(l_positive[\u001b[38;5;241m0\u001b[39m, :, :, :, :], model)\n\u001b[0;32m     32\u001b[0m dist\u001b[38;5;241m=\u001b[39meuc_dis(f_d, pos)\n",
      "Cell \u001b[1;32mIn [61], line 2\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(image, model):\n\u001b[1;32m----> 2\u001b[0m   c_im\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m c_im\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2475\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_predict_function()\n\u001b[0;32m   2474\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function(iterator)\n\u001b[1;32m-> 2475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## ph_comp=cv2.imread(\"./positive_anchor/photo_compare.jpg\")\n",
    "import sklearn\n",
    "def euc_dis(p1, p2):\n",
    "    sum_sq = np.sum(np.square(p1-p2))\n",
    "    return np.sqrt(sum_sq)\n",
    "im=face_detector(\"./positive_anchor/test_2.jpg\")\n",
    "if im is not None:\n",
    "    f_d=convert(im, model)\n",
    "    dist=euc_dis(f_d,convert(l_positive[0, :, :, :, :], model))\n",
    "    dist=dist*6\n",
    "    print(dist)\n",
    "vid = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    # Display the resulting frame\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    for (x, y, w, h) in faces:\n",
    "        photo=frame[y:y+h,x:x+w, :]\n",
    "        \n",
    "        cv2.imshow('frame', photo)\n",
    "        \n",
    "        im_=cv2.resize(photo, (160, 160))\n",
    "        im_=im_.astype(np.float32)\n",
    "        im_=(im_-np.mean(im_))/np.std(im_)\n",
    "        f_d=convert(im_, model)\n",
    "        pos=convert(l_positive[0, :, :, :, :], model)\n",
    "        dist=euc_dis(f_d, pos)\n",
    "        dist=dist*6\n",
    "        print(dist)\n",
    "        if dist>0.6:\n",
    "            print(\"unable\")\n",
    "        else:\n",
    "            print(\"success\")\n",
    "\n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_weights('weights')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a752f9f72ac1a83d5296529fa8e6340d8cfe3d3d67b359f51c51a0696ebeb14a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
